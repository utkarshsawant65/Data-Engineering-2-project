{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install schedule\n",
        "!pip install requests\n",
        "\n",
        "!pip install datetime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05ys-AH7qnEX",
        "outputId": "dbf3a66b-3d62-4518-ddf7-47e434a23263"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting schedule\n",
            "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.2.2\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Collecting datetime\n",
            "  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting zope.interface (from datetime)\n",
            "  Downloading zope.interface-7.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from datetime) (2024.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->datetime) (75.1.0)\n",
            "Downloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zope.interface-7.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.5/254.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zope.interface, datetime\n",
            "Successfully installed datetime-5.5 zope.interface-7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxz-0cT6qYv8",
        "outputId": "61aeee12-4627-4345-9f39-79b8708aded6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data for the first time...\n",
            "Data successfully updated. Added 3996 new rows.\n",
            "Scheduler is running. Press Ctrl+C to stop.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import csv\n",
        "import schedule\n",
        "import time\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Constants\n",
        "STOCK_FILENAME = \"google_stock_data.csv\"\n",
        "LOG_FILENAME = \"update_log_google.txt\"\n",
        "API_URL = 'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=GOOGL&interval=5min&outputsize=full&apikey=J30SRXLUMQK4EW8Y'\n",
        "\n",
        "# Function to load existing timestamps from the stock data file\n",
        "def load_existing_timestamps():\n",
        "    if not os.path.exists(STOCK_FILENAME):\n",
        "        return set()\n",
        "    with open(STOCK_FILENAME, mode=\"r\") as file:\n",
        "        reader = csv.reader(file)\n",
        "        next(reader)  # Skip header\n",
        "        return {row[0] for row in reader}  # Collect all timestamps\n",
        "\n",
        "# Function to fetch and update stock data\n",
        "def fetch_stock_data():\n",
        "    # Fetch data from the API\n",
        "    r = requests.get(API_URL)\n",
        "    data = r.json()\n",
        "\n",
        "    if \"Time Series (5min)\" in data:\n",
        "        time_series = data[\"Time Series (5min)\"]\n",
        "\n",
        "        # Load existing timestamps to avoid duplication\n",
        "        existing_timestamps = load_existing_timestamps()\n",
        "\n",
        "        # Prepare rows for new data\n",
        "        new_rows = []\n",
        "        for timestamp, values in time_series.items():\n",
        "            if timestamp not in existing_timestamps:\n",
        "                new_rows.append([\n",
        "                    timestamp,\n",
        "                    values[\"1. open\"],\n",
        "                    values[\"2. high\"],\n",
        "                    values[\"3. low\"],\n",
        "                    values[\"4. close\"],\n",
        "                    values[\"5. volume\"]\n",
        "                ])\n",
        "\n",
        "        if new_rows:\n",
        "            # Append new rows to the file\n",
        "            file_exists = os.path.exists(STOCK_FILENAME)\n",
        "            with open(STOCK_FILENAME, mode=\"a\", newline=\"\") as file:\n",
        "                writer = csv.writer(file)\n",
        "                if not file_exists:\n",
        "                    # Write header if the file is new\n",
        "                    header = [\"Timestamp\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
        "                    writer.writerow(header)\n",
        "                writer.writerows(new_rows)\n",
        "\n",
        "            # Log the update\n",
        "            with open(LOG_FILENAME, mode=\"a\") as log_file:\n",
        "                log_file.write(f\"{datetime.now()}: Added {len(new_rows)} new rows to {STOCK_FILENAME}\\n\")\n",
        "            print(f\"Data successfully updated. Added {len(new_rows)} new rows.\")\n",
        "        else:\n",
        "            print(\"No new data to update.\")\n",
        "    else:\n",
        "        print(\"Error: Time Series data not found in the response\")\n",
        "\n",
        "# Schedule the task to run every hour\n",
        "schedule.every(1).hour.do(fetch_stock_data)\n",
        "\n",
        "# Run the function immediately for the first iteration\n",
        "print(\"Fetching data for the first time...\")\n",
        "fetch_stock_data()\n",
        "\n",
        "print(\"Scheduler is running. Press Ctrl+C to stop.\")\n",
        "\n",
        "# Keep the script running to execute the scheduler\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(1)\n"
      ]
    }
  ]
}